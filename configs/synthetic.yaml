### Input
# input rgba image path (default to None, can be load in GUI too)
input: 
# input text prompt (default to None, can be input in GUI too)
prompt:
negative_prompt:
ref_size: 1024

### Training
# guidance loss weights (0 to disable)
lambda_sd: 0
mvdream: False
lambda_zero123: 0.1
stable_zero123: True
# training iterations for stage 1
iters: 500
# whether to linearly anneal timestep
anneal_timestep: True
batch_size: 1
# training camera radius
radius: 2
# training camera fovy
fovy: 75 # align with zero123 rendering setting (ref: https://github.com/cvlab-columbia/zero123/blob/main/objaverse-rendering/scripts/blender_script.py#L61
# checkpoint to load for stage 1 (should be a ply file)
load:
# prob to invert background color during training (0 = always black, 1 = always white)
invert_bg_prob: 0.5

### GUI
gui: False
force_cuda_rast: True
# GUI resolution
H: 1024
W: 1024
zfc_num: 1000
pce_num: 10000
ver_std: 15
hor_std: 45 
ver_mean: 60
hor_mean: 180
scale_denom: 10.0
densify_N: 4
pose_weight: 0.0008
scale_weight: 100
box_size: 1.3

### Gaussian splatting
sh_degree: 0
position_lr_init: 0.001
position_lr_final: 0.00002
position_lr_delay_mult: 0.02
position_lr_max_steps: 500
feature_lr: 0.01
opacity_lr: 0.01
scaling_lr: 0.01
rotation_lr: 0.005
densification_interval: 501
densify_grad_threshold: 0
